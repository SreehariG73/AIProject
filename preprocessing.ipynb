{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreehariguruprasad/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **1. Preprocessing**\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract raw text from a PDF resume\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text) \n",
    "    return text\n",
    "\n",
    "def create_features(resumes):\n",
    "    vectorizer = CountVectorizer()  # Or use TfidfVectorizer()\n",
    "    features = vectorizer.fit_transform([resume['text'] for resume in resumes])\n",
    "    return features, vectorizer.get_feature_names_out()\n",
    "\n",
    "def extract_skills(text, nlp):\n",
    "    skills = []\n",
    "\n",
    "    # NER for skill-like entities\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['SKILL']:  # Customize if your NER has other labels\n",
    "            skills.append(ent.text)\n",
    "\n",
    "    # Keyword Matching (customize this list extensively)\n",
    "    skill_keywords = [\"Python\", \"Java\", \"data analysis\", \"machine learning\", ...]\n",
    "    for word in text.split():\n",
    "        if word.lower() in skill_keywords:\n",
    "            skills.append(word)\n",
    "\n",
    "    return list(set(skills))\n",
    "\n",
    "def extract_experience(text, nlp):\n",
    "    experiences = []\n",
    "    doc = nlp(text)\n",
    "    # Job title search (NER or matching)\n",
    "    job_titles = [ent.text for ent in doc.ents if ent.label_ == 'JOB_TITLE']  # Customize label\n",
    "\n",
    "    # Date pattern searching\n",
    "    date_pattern = r'\\d{4}|((Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\.?\\s\\d{4})'\n",
    "    date_ranges = re.findall(date_pattern, text) \n",
    "\n",
    "    # Combine into potential experiences \n",
    "    for job_title, date_range in zip(job_titles, date_ranges):\n",
    "        experiences.append({\n",
    "            'title': job_title,\n",
    "            'date_range': date_range\n",
    "        })\n",
    "\n",
    "    return experiences\n",
    "\n",
    "def extract_education(text, nlp):\n",
    "    education_info = []\n",
    "    doc = nlp(text)\n",
    "    # Degree pattern matching\n",
    "    degree_pattern = r'\\b([A-Z][a-z]+\\s?)+(\\sDegree\\b|\\b[Bb]achelor\\b|\\b[Mm]aster\\b|\\b[Dd]octorate\\b)'\n",
    "    degrees = re.findall(degree_pattern, text)\n",
    "\n",
    "    # University/Institution search (may need NER tuning)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['ORG']:  # Assuming 'ORG' tag represents institutions\n",
    "            education_info.append({\n",
    "                'institution': ent.text,\n",
    "                'degrees': degrees  # Associate degrees if found nearby\n",
    "            })\n",
    "\n",
    "    return education_info \n",
    "\n",
    "\n",
    "def load_and_label_data(data_dir):\n",
    "    resumes = []\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.pdf'):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "            text = preprocess_text(text)\n",
    "            skills = extract_skills(text, nlp)\n",
    "\n",
    "            # Education Extraction\n",
    "            education = extract_education(text, nlp)\n",
    "\n",
    "            # Experience Extraction\n",
    "            experience = extract_experience(text, nlp)\n",
    "            resumes.append({\n",
    "                'text': text,\n",
    "                'skills': skills,\n",
    "                'education': education,\n",
    "                'experience': experience\n",
    "            })\n",
    "    return resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x4/sd3bc1s15jxdbxm6r5jkp6sr0000gn/T/ipykernel_12121/3250514777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimilarity_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text-classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_description_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Calculates a similarity score between resume and job description\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{resume_text} [SEP] {job_description_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "similarity_classifier = pipeline('text-classification', model=AutoModelForSequenceClassification.from_pretrained(model_name))\n",
    "def calculate_similarity(resume_text, job_description_text):\n",
    "    \"\"\"Calculates a similarity score between resume and job description\"\"\"\n",
    "    result = similarity_classifier(f\"{resume_text} [SEP] {job_description_text}\")\n",
    "    score = result[0]['score']  # Assuming the model provides a score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_resume' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x4/sd3bc1s15jxdbxm6r5jkp6sr0000gn/T/ipykernel_12121/998050924.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mjob_description_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_description_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_resume' is not defined"
     ]
    }
   ],
   "source": [
    "resume_path = '/Users/sreehariguruprasad/myprojects/AI Project/resume dataset/data/Test'\n",
    "job_description_path = '/Users/sreehariguruprasad/myprojects/AI Project/job_description.txt'  # Assume job description is in text\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "resume = load_and_label_data(resume_path)\n",
    "job_description_text = open(job_description_path, 'r').read()  \n",
    "\n",
    "similarity_score = calculate_similarity(resume['text'], job_description_text)\n",
    "print(f\"Similarity Score: {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
